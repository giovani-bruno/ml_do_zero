{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como funciona o modelo Naive Bayes?\n",
    "O Naive Bayes é um algoritmo de classificação baseado no Teorema de Bayes, que calcula a probabilidade de um evento ocorrer com base em informações anteriores. No caso do filtro de spam, queremos calcular:\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "P(Spam∣Palavras da Mensagem)\n",
    "$$\n",
    "<br>\n",
    "Ou seja, a probabilidade de uma mensagem ser spam, dado que ela contém certas palavras.\n",
    "\n",
    "Para isso, precisamos calcular duas probabilidades:\n",
    "\n",
    "P(Palavra | Spam) -> A chance de uma palavra aparecer em mensagens de spam.\n",
    "\n",
    "P(Palavra | Não Spam) -> A chance da mesma palavra aparecer em mensagens normais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O conceito de \"Ingênuo\" no Naive Bayes\n",
    "O nome Naive (ingênuo) vem de uma suposição forte: as palavras dentro de uma mensagem são consideradas independentes entre si.\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "Sabemos que palavras como \"bitcoin\" e \"rolex\" aparecem frequentemente em spams.\n",
    "No mundo real, se uma mensagem contém \"bitcoin\", é provável que \"rolex\" também apareça.\n",
    "Mas no Naive Bayes, essas palavras são tratadas como independentes.\n",
    "Matematicamente, isso significa que:\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "P(\"bitcoin\" e \"rolex\"∣Spam) = P(\"bitcoin\"∣Spam) × P(\"rolex\"∣Spam)\n",
    "$$\n",
    "<br>\n",
    "Essa suposição pode ser irrealista, mas o modelo funciona muito bem na prática e é usado em filtros de spam reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como calcular a probabilidade de uma mensagem ser spam?\n",
    "O modelo usa o Teorema de Bayes:\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "P(Spam∣Palavras) = \\frac{P(Palavras∣Spam) × P(Spam)}{P(Palavras)}\n",
    "$$\n",
    "​<br>\n",
    "Mas, como calcular P(Palavras∣Spam)?\n",
    "\n",
    "Simples: multiplicamos a probabilidade de cada palavra individual aparecer em um spam.\n",
    "\n",
    "Problema: Multiplicar muitas probabilidades pequenas pode causar problemas numéricos no computador, pois eles não processam bem os números de ponto flutuante muito próximos de 0.\n",
    "\n",
    "Solução: Em vez de multiplicar, usamos logaritmos, pois somar logs evita números muito pequenos.\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "logP(Spam∣Palavras)=∑logP(Palavra∣Spam)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Problema das Probabilidades ZEROS e a Suavização\n",
    "Se uma palavra nunca apareceu em mensagens de spam no nosso conjunto de treino, teríamos:\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "P(bitcoin∣Spam)=0\n",
    "$$\n",
    "<br>\n",
    "Isso faria o modelo atribuir probabilidade 0 a qualquer mensagem que contivesse essa palavra, o que não é desejável.\n",
    "\n",
    "Para resolver isso, usamos a suavização de Laplace (ou pseudocontagem k):\n",
    "\n",
    "$$\n",
    "P(Palavra∣Spam)=\\frac{ k + contagem da palavra em spams}{2k+total de spams}\n",
    "$$\n",
    "​\n",
    " \n",
    "Isso garante que nenhuma palavra tenha probabilidade zero, permitindo ao modelo lidar melhor com palavras raras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o Modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb import Message, NaiveBayesClassifier\n",
    "\n",
    "messages = [Message(\"spam rules\", is_spam=True),\n",
    "            Message(\"ham rules\", is_spam=False), # os hams são os não spams\n",
    "            Message(\"hello ham\", is_spam=False)]\n",
    "\n",
    "model = NaiveBayesClassifier(k=0.5)\n",
    "model.train(messages)\n",
    "\n",
    "# Verificando se as contagens estão corretas\n",
    "assert model.tokens == {\"spam\", \"ham\", \"rules\", \"hello\"}\n",
    "assert model.spam_messages == 1\n",
    "assert model.ham_messages == 2\n",
    "assert model.token_spam_counts == {\"spam\": 1, \"rules\": 1}\n",
    "assert model.token_ham_counts == {\"ham\": 2, \"rules\": 1, \"hello\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precisamos analisar a lógica do Naive Bayes manualmente e verificar se obtemos o mesmo resultado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8350515463917525\n",
      "0.8350515463917525\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "texto = \"hello spam\"\n",
    "\n",
    "probs_se_spam = [\n",
    "    (1 + 0.5) / (1 + 2 * 0.5),      # \"spam\"  (presente)\n",
    "    1 - (0 + 0.5) / (1 + 2 * 0.5),  # \"ham\"   (ausente)\n",
    "    1 - (1 + 0.5) / (1 + 2 * 0.5),  # \"rules\" (ausente)\n",
    "    (0 + 0.5) / (1 + 2 * 0.5)       # \"hello\" (presente)\n",
    "]\n",
    "\n",
    "probs_se_ham = [\n",
    "    (0 + 0.5) / (2 + 2 * 0.5),      # \"spam\"  (presente)\n",
    "    1 - (2 + 0.5) / (2 + 2 * 0.5),  # \"ham\"   (ausente)\n",
    "    1 - (1 + 0.5) / (2 + 2 * 0.5),  # \"rules\" (ausente)\n",
    "    (1 + 0.5) / (2 + 2 * 0.5),      # \"hello\" (presente)\n",
    "]\n",
    "\n",
    "p_se_spam = math.exp(sum(math.log(p) for p in probs_se_spam))\n",
    "p_se_ham = math.exp(sum(math.log(p) for p in probs_se_ham))\n",
    "\n",
    "# Deve ser aproximadamente 0.83\n",
    "print(model.predict(texto))\n",
    "print(p_se_spam / (p_se_spam + p_se_ham))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parece que o modelo passou no teste. Agora, utilizaremos dados reais.\n",
    "Os dados estão na pasta 'dados_spam', dentro dessa pasta tem outras três pastas: spam, easy_ham e hard_ham. Cada uma dessas pastas contém muitos e-mails, e cada e-mail fica em um arquivo. Para simplificar, usaremos apenas a linha de assunto de cada e-mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(text='Re: New Sequences Window\\n', is_spam=False),\n",
       " Message(text='[zzzzteana] RE: Alexander\\n', is_spam=False),\n",
       " Message(text='[zzzzteana] Moscow bomber\\n', is_spam=False),\n",
       " Message(text=\"[IRR] Klez: The Virus That  Won't Die\\n\", is_spam=False),\n",
       " Message(text='Re: Insert signature\\n', is_spam=False)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from glob import glob\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import tarfile\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "URL = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
    "ARQUIVOS = [\"20021010_easy_ham.tar.bz2\", \"20021010_hard_ham.tar.bz2\", \"20021010_spam.tar.bz2\"]\n",
    "DIR_SAIDA = 'Naive Bayes/dados_spam'\n",
    "\n",
    "for arquivo in ARQUIVOS:\n",
    "    conteudo = requests.get(f\"{URL}/{arquivo}\").content\n",
    "    fin = BytesIO(conteudo)\n",
    "    with tarfile.open(fileobj=fin, mode='r:bz2') as tf:\n",
    "        tf.extractall(DIR_SAIDA)\n",
    "\n",
    "caminho = 'dados_spam/*/*'\n",
    "\n",
    "dados: List[Message] = []\n",
    "\n",
    "for filename in glob(caminho):\n",
    "    is_spam = \"ham\" not in filename\n",
    "\n",
    "    with open(filename, errors='ignore') as email_file:\n",
    "        for line in email_file:\n",
    "            if line.startswith(\"Subject:\"):\n",
    "                subject = line.lstrip(\"Subject: \")\n",
    "                dados.append(Message(subject, is_spam))\n",
    "\n",
    "                break\n",
    "\n",
    "dados[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2475, 825)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypeVar, Tuple\n",
    "import random\n",
    "\n",
    "X = TypeVar('X')  # tipo genérico para representar um ponto de dados\n",
    "\n",
    "def dividir_dados(dados: List[X], prop: float) -> Tuple[List[X], List[X]]:\n",
    "    \"\"\"Divide os dados em frações [prop, 1 - prop]\"\"\"\n",
    "    dados = dados[:]                    # Faz uma cópia rasa\n",
    "    random.shuffle(dados)               # porque shuffle modifica a lista.\n",
    "    corte = int(len(dados) * prop)  # Usa a prop para encontrar o ponto de corte\n",
    "    return dados[:corte], dados[corte:]\n",
    "\n",
    "random.seed(0) # para reproduzir os mesmos resultados\n",
    "train_messages, test_messages = dividir_dados(dados, 0.75)\n",
    "\n",
    "assert len(train_messages) == 0.75 * len(dados)\n",
    "assert len(test_messages) == 0.25 * len(dados)\n",
    "len(train_messages), len(test_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(False, False): 670,\n",
       "         (True, True): 86,\n",
       "         (True, False): 40,\n",
       "         (False, True): 29})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "modelo = NaiveBayesClassifier()\n",
    "modelo.train(train_messages)\n",
    "\n",
    "previsoes = [(mensagem, modelo.predict(mensagem.text)) for mensagem in test_messages]\n",
    "\n",
    "confusion_matrix = Counter((mensagem.is_spam, probabilidade_spam > 0.5) for mensagem, probabilidade_spam in previsoes)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com nosso modelo naive bayes criado do zero, obtivemos 670 negativos verdadeiros (hams classificados como hams), 86 verdadeiros positivos (spams classificados como spams), 40 negativos falsos (spams classificados como hams) e 29 positivos falsos (hams classificados como spams). Então a precisão e a sensibilidade são:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7478260869565218 0.6825396825396826\n"
     ]
    }
   ],
   "source": [
    "precision = 86 / (86 +29)\n",
    "recall = 86 / (86 + 40)\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E a acurácia é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9163636363636364"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acertos = 0\n",
    "\n",
    "for bool1, bool2 in confusion_matrix.keys(): \n",
    "    if bool1 == bool2: # verdadeiro positivo ou verdadeiro negativo, ou seja, os acertos\n",
    "        acertos += confusion_matrix[(bool1, bool2)]\n",
    "\n",
    "accuracy = acertos / len(test_messages)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora, chegou a hora de comparar nosso modelo com o do scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o modelo BernoulliNB do scikit-learn não consegue trabalhar diretamente com textos, temos que usar o CountVectorizer com binary=True, que cria uma matriz onde cada palavra única vira uma coluna, e cada mensagem é representada por um vetor binário (1 se a palavra está presente, 0 se não está). Isso permite que o modelo use probabilidades para classificar mensagens como spam ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n",
      "[[695   2]\n",
      " [ 97  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      1.00      0.93       697\n",
      "        True       0.94      0.24      0.39       128\n",
      "\n",
      "    accuracy                           0.88       825\n",
      "   macro avg       0.91      0.62      0.66       825\n",
      "weighted avg       0.89      0.88      0.85       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "X = [assunto.text for assunto in dados]  # Textos das mensagens\n",
    "y = [assunto.is_spam for assunto in dados]  # Rótulos (spam ou não)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Convertendo o texto em uma matriz de presença/ausência de palavras\n",
    "vectorizer = CountVectorizer(binary=True)  # binário pois é para BernoulliNB\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "nb_sklearn = BernoulliNB()\n",
    "nb_sklearn.fit(X_train_vec, y_train)\n",
    "\n",
    "previsoes_sklearn = nb_sklearn.predict(X_test_vec)\n",
    "\n",
    "accuracy_sklearn = accuracy_score(y_test, previsoes_sklearn)\n",
    "confusion_matrix_sklearn = confusion_matrix(y_test, previsoes_sklearn)\n",
    "classification_report_sklearn = classification_report(y_test, previsoes_sklearn)\n",
    "\n",
    "print(accuracy_sklearn, confusion_matrix_sklearn, classification_report_sklearn, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso modelo Naive Bayes implementado do zero obteve uma acurácia de 91%, enquanto a versão do scikit-learn (BernoulliNB) alcançou 88%.\n",
    "\n",
    "Isso mostra que nossa implementação conseguiu um desempenho ligeiramente melhor, o que pode ter sido influenciado por escolhas específicas no pré-processamento dos dados ou na suavização das probabilidades. No entanto, a diferença não é tão grande, e o modelo do scikit-learn tem a vantagem de ser otimizado, mais rápido e pronto para uso em aplicações reais.\n",
    "\n",
    "Analisando a matriz de confusão do sklearn, vemos que o modelo classificou corretamente 695 hams (Verdadeiros negativos) e 31 spams (Verdadeiros positivos). No entanto, ele cometeu 97 erros ao classificar spams como hams (Falsos negativos), o que sugere que ele tem dificuldade em identificar spams corretamente.\n",
    "\n",
    "O classification report reforça essa observação:\n",
    "\n",
    "A precisão (precision) para a classe spam (True) é 0.94, o que significa que, das mensagens classificadas como spam, 94% eram realmente spams.\n",
    "O recall para a classe spam é 0.24, indicando que o modelo só identificou corretamente 24% dos spams. Isso mostra que o modelo é conservador ao classificar uma mensagem como spam e acaba errando muito ao não identificar spams corretamente.\n",
    "Para a classe ham (False), o recall é 1.00, ou seja, o modelo praticamente não classifica hams como spams, sendo muito confiável na detecção de mensagens legítimas.\n",
    "\n",
    "A métrica F1-score (média harmônica entre precisão e recall) para spam ficou em 0.39, mostrando que o modelo tem dificuldades em equilibrar precisão e recall.\n",
    "\n",
    "Em resumo, conseguimos validar que a abordagem teórica do Naive Bayes funciona bem na prática, e nossa implementação manual demonstrou um excelente desempenho, comparável a uma biblioteca amplamente usada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chegamos ao fim de mais uma implementação manual de um modelo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
